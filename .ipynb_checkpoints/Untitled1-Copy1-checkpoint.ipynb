{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "from word2number import w2n\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sceris_files = os.listdir('sceris_data')\n",
    "sceris_files = {s.split('_')[0]: s for s in sceris_files if 'DS_Store' not in s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_raw/STRbldgsGPSplus.csv')\n",
    "\n",
    "# this needs to be identical to the operation in the scraper file\n",
    "\n",
    "def parse_st_num(x):\n",
    "    f_char = x.split()[0]\n",
    "    if any(w in f_char for w in ['One']):\n",
    "        return str(w2n.word_to_num(x) )\n",
    "    else:\n",
    "        try:  return f'{f_char}-{int(x.split()[1])}'\n",
    "        except: return f'{f_char}'\n",
    "        \n",
    "def parse_st_name(x):\n",
    "    try:\n",
    "        int(x.split()[1])\n",
    "        return x.split()[2]\n",
    "    except:\n",
    "        return x.split()[1]\n",
    "    \n",
    "df['st_name'] = df.GPSaddress.apply(parse_st_name)\n",
    "df['st_num'] = df.GPSaddress.apply(parse_st_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[123, 2348]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([123, 2348])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_direct_matches(max_search_rad=60, min_nearbys=10, search_step=15):\n",
    "    out = pd.DataFrame()\n",
    "    found = 0\n",
    "    no_st_data = 0\n",
    "    no_st_bldgs = 0\n",
    "    no_bldg_data = 0\n",
    "    # iterate by streets\n",
    "    for st_name in tqdm(df.st_name.unique()):\n",
    "        st_data = df[df.st_name==st_name]\n",
    "        bldg_ct = st_data.st_num.nunique()\n",
    "\n",
    "        if st_name not in sceris_files.keys():\n",
    "            no_st_data += 1\n",
    "            no_st_bldgs += len(st_data)\n",
    "            continue\n",
    "\n",
    "        # load sceris data for street\n",
    "        sceris_data = pd.read_csv('sceris_data/'+sceris_files[st_name])\n",
    "\n",
    "        # iterate buildings\n",
    "        for st_num in st_data.st_num.sort_values().unique():\n",
    "            matches = pd.DataFrame()\n",
    "            \n",
    "            # id building  or bldg group by index in df\n",
    "            bldg_idx = df[(df.st_name==st_name) & (df.st_num==st_num)].index[0]\n",
    "            address_street = df.loc[bldg_idx, 'GPSaddress'].lower().strip()\n",
    "            \n",
    "            # search multiple st numbers if range\n",
    "            range_search = False\n",
    "            if '-' in st_num:\n",
    "                st_num = st_num.split('-')\n",
    "                try:\n",
    "                    s_parts = sorted([int(st_num[0]), int(st_num[1])])\n",
    "                    search = range(s_parts[0], s_parts[1])\n",
    "                    range_search = True\n",
    "                except:\n",
    "                    try:\n",
    "                        search = [int(''.join(re.findall('[\\d]*', st_num[0])))]\n",
    "                    except:\n",
    "                        print('**Hiccupped at', st_num, st_name,)\n",
    "                        continue\n",
    "            # create single-item range otherwise (for now)\n",
    "            else:\n",
    "                try:\n",
    "                    search = [int(''.join(re.findall('[\\d]*', st_num)))]\n",
    "                except:\n",
    "                    print('**Hiccupped at', st_num, st_name,)\n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "            # search sceris documents for numbers in given range\n",
    "            for sub_num in search:\n",
    "                # isolate for matches in sceris street number\n",
    "                submatch = sceris_data[sceris_data['Primary Street Number']==sub_num].copy()\n",
    "                if len(submatch)>0:\n",
    "                    submatch_street = submatch['Street Name'].values[0].lower().strip()\n",
    "                    fscore = fuzz.partial_ratio(address_street,\n",
    "                                       submatch_street)\n",
    "                    # street name partial fscore for sanity check \n",
    "                    if fscore>90:\n",
    "                        matches = pd.concat([matches, submatch])\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "            # Search with secondary Sceris st num\n",
    "            if len(matches)==0:\n",
    "                for sub_num in search:\n",
    "                    # isolate for matches in sceris street number\n",
    "                    submatch = sceris_data[sceris_data['Secondary Street Number']==sub_num].copy()\n",
    "                    if len(submatch)>0:\n",
    "                        submatch_street = submatch['Street Name'].values[0].lower().strip()\n",
    "                        fscore = fuzz.partial_ratio(address_street,\n",
    "                                           submatch_street)\n",
    "                        # street name partial fscore for sanity check \n",
    "                        if fscore>90:\n",
    "                            matches = pd.concat([matches, submatch])\n",
    "\n",
    "            \n",
    "            \n",
    "            # expand search if no exact matches found\n",
    "            if len(matches)==0:\n",
    "                search_rad = 0\n",
    "                while len(matches)<min_nearbys and search_rad<=max_search_rad:\n",
    "                    if search_rad>=max_search_rad:\n",
    "                        break\n",
    "                    search_rad+=search_step\n",
    "                    if len(search)>1: # range\n",
    "                        expanded = list(range(max(0, min(search)-search_rad), min(search))\n",
    "                                       ) + list(range(max(search), max(search)+search_rad))\n",
    "                    else:\n",
    "                        expanded = range(max(0, search[0]-search_rad), search[0]+search_rad)                \n",
    "                    for sub_num in expanded:\n",
    "                        # isolate for matches in sceris street number\n",
    "                        submatch = sceris_data[sceris_data['Primary Street Number']==sub_num].copy()\n",
    "                        if len(submatch)>0:\n",
    "                            submatch_street = submatch['Street Name'].values[0].lower().strip()\n",
    "                            fscore = fuzz.partial_ratio(address_street,\n",
    "                                               submatch_street)\n",
    "                            # street name partial fscore for sanity check \n",
    "                            if fscore>90:\n",
    "                                matches = pd.concat([matches, submatch])\n",
    "\n",
    "                        \n",
    "            # save\n",
    "            if len(matches)>0:\n",
    "                matches['adco_index'] = bldg_idx  \n",
    "                out = pd.concat([out, matches]) \n",
    "                found += 1\n",
    "            else: # log\n",
    "                no_bldg_data += 1\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "    print(f'Found {len(out)} documents for {found} buildings')\n",
    "    print(f'  > {no_st_data} streets have no C/O data ({no_st_bldgs} buildings)')\n",
    "    print(f'  > {no_bldg_data} buildings have no exact st number matches')\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93859663916461787dae66278394b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=114.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = find_direct_matches()\n",
    "print('Dropping', out.duplicated().sum(), 'duplicates...')\n",
    "out = out.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[:2]]\n",
    "merged = pd.merge(df, out,\n",
    "                  left_on=df.index, right_on='adco_index')\n",
    "merged.to_csv('sceris_adco_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
